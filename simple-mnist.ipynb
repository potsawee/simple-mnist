{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Settting\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # choose the device (GPU) here\n",
    "sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess_config.gpu_options.allow_growth = True # Whether the GPU memory usage can grow dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and dev sets\n",
    "with open('data/train.csv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "num = len(lines) - 1\n",
    "x = np.zeros(shape=(num,784))\n",
    "y = np.zeros(shape=(num))\n",
    "\n",
    "lines = lines[1:] # ignore pixel0, pixel1,...\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "for i, line in enumerate(lines[1:]):\n",
    "    items = line.strip().split(',')\n",
    "    y[i] = int(items[0])\n",
    "    for j, val in enumerate(items[1:]):\n",
    "        x[i,j] = int(val)\n",
    "        \n",
    "x_train = x[:40000]\n",
    "y_train = y[:40000]\n",
    "x_dev = x[40000:]\n",
    "y_dev = y[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "40000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_dev))\n",
    "print(len(y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "with open('data/test.csv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "num = len(lines) - 1\n",
    "x_test = np.zeros(shape=(num,784))\n",
    "for i, line in enumerate(lines[1:]):\n",
    "    items = line.strip().split(',')\n",
    "    for j, val in enumerate(items):\n",
    "        x_test[i,j] = int(val)\n",
    "        \n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 7.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 24\n",
    "imshow(x_train[idx].reshape(28,28))\n",
    "print('label =', y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed-forward neural network\n",
    "def build_ff_model(x):\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [784, 250], initializer=tf.glorot_normal_initializer())\n",
    "    b1 = tf.get_variable(\"b1\", [250], initializer=tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [250, 10], initializer=tf.glorot_normal_initializer())\n",
    "    b2 = tf.get_variable(\"b2\", [10], initializer=tf.zeros_initializer())\n",
    "\n",
    "    # computation\n",
    "    z1 = tf.matmul(x, W1) + b1\n",
    "    a1 = tf.nn.tanh(z1)\n",
    "\n",
    "    z2 = tf.matmul(a1, W2) + b2\n",
    "    nn_output = tf.nn.softmax(z2)\n",
    "\n",
    "    return nn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network\n",
    "def build_cnn_model(x):\n",
    "    \n",
    "    s = tf.shape(x)\n",
    "    x1 = tf.reshape(x, shape=(s[0], 28, 28, 1))\n",
    "\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    layer_conv1, weights_conv1 = new_conv_layer(\n",
    "        input=x1, num_input_channels=1, \n",
    "        filter_size=5, num_filters=6, name =\"conv1\")\n",
    "    # RelU layer 1\n",
    "    layer_relu1 = new_relu_layer(layer_conv1, name=\"relu1\")\n",
    "    # Pooling Layer 1\n",
    "    layer_pool1 = new_pool_layer(layer_relu1, name=\"pool1\")\n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    layer_conv2, weights_conv2 = new_conv_layer(\n",
    "        input=layer_pool1, num_input_channels=6, \n",
    "        filter_size=5, num_filters=16, name= \"conv2\")\n",
    "    # RelU layer 2\n",
    "    layer_relu2 = new_relu_layer(layer_conv2, name=\"relu2\")\n",
    "    # Pooling Layer 2\n",
    "    layer_pool2 = new_pool_layer(layer_relu2, name=\"pool2\")\n",
    "\n",
    "\n",
    "    # Flatten Layer\n",
    "    num_features = layer_pool2.get_shape()[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(layer_pool2, [-1, num_features])\n",
    "\n",
    "    # Fully-Connected Layer 1\n",
    "    layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=128, name=\"fc1\")\n",
    "\n",
    "    # RelU layer 3\n",
    "    layer_relu3 = new_relu_layer(layer_fc1, name=\"relu3\")\n",
    "\n",
    "    # Fully-Connected Layer 2\n",
    "    layer_fc2 = new_fc_layer(input=layer_relu3, num_inputs=128, num_outputs=10, name=\"fc2\")\n",
    "\n",
    "    # Softmax\n",
    "    nn_output = tf.nn.softmax(layer_fc2)\n",
    "    \n",
    "    return nn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiment(build_nn_model, batch_size, num_epochs):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name=\"x\")\n",
    "    y = tf.placeholder(tf.int32, [None], name=\"y\")\n",
    "\n",
    "    nn_output = build_nn_model(x)\n",
    "\n",
    "    # loss function\n",
    "    onehot = tf.one_hot(y, 10, dtype=tf.float32)\n",
    "    loss = -1.0 * tf.reduce_mean( onehot * tf.log(nn_output) )\n",
    "\n",
    "    # training op\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "    # evaluation\n",
    "    correct_pred = tf.equal(tf.argmax(nn_output, 1, output_type=tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "#     batch_size = 1024\n",
    "    train_size = len(x_train)\n",
    "\n",
    "    # ---------------------- #\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    # ---------------------- #\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    with tf.Session(config=sess_config) as sess:\n",
    "        # writer\n",
    "        summary_writer = tf.summary.FileWriter('mnist_logs/', graph_def=sess.graph_def)\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(int(train_size/batch_size)):\n",
    "                feed_dict = {x: x_train[i*batch_size:(i+1)*batch_size],\n",
    "                             y: y_train[i*batch_size:(i+1)*batch_size]}\n",
    "                train_loss, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "                if i % 10 == 0:\n",
    "\n",
    "                     # write something\n",
    "                     summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "                     summary_writer.add_summary(summary_str, counter)\n",
    "                     counter += 1\n",
    "\n",
    "            feed_dict = {x: x_dev, y: y_dev}\n",
    "            [acc] = sess.run([accuracy], feed_dict=feed_dict)\n",
    "            print(\"epoch: {} --- accuracy: {}\".format(epoch, acc*100))\n",
    "\n",
    "\n",
    "        feed_dict = {x: x_test}\n",
    "        [outputs] = sess.run([nn_output], feed_dict=feed_dict)\n",
    "        \n",
    "        y_preds = np.argmax(outputs, axis=1)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "epoch: 0 --- accuracy: 90.04999995231628\n",
      "epoch: 1 --- accuracy: 90.70000052452087\n",
      "epoch: 2 --- accuracy: 92.40000247955322\n",
      "epoch: 3 --- accuracy: 92.5499975681305\n",
      "epoch: 4 --- accuracy: 93.09999942779541\n",
      "epoch: 5 --- accuracy: 92.84999966621399\n",
      "epoch: 6 --- accuracy: 93.04999709129333\n",
      "epoch: 7 --- accuracy: 93.34999918937683\n",
      "epoch: 8 --- accuracy: 93.4000015258789\n",
      "epoch: 9 --- accuracy: 93.30000281333923\n",
      "epoch: 10 --- accuracy: 93.30000281333923\n",
      "epoch: 11 --- accuracy: 94.45000290870667\n",
      "epoch: 12 --- accuracy: 94.24999952316284\n",
      "epoch: 13 --- accuracy: 93.90000104904175\n",
      "epoch: 14 --- accuracy: 94.24999952316284\n",
      "epoch: 15 --- accuracy: 94.15000081062317\n",
      "epoch: 16 --- accuracy: 93.99999976158142\n",
      "epoch: 17 --- accuracy: 94.15000081062317\n",
      "epoch: 18 --- accuracy: 94.49999928474426\n",
      "epoch: 19 --- accuracy: 93.80000233650208\n"
     ]
    }
   ],
   "source": [
    "y_ff_preds = experiment(build_ff_model, batch_size=512, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "epoch: 0 --- accuracy: 93.84999871253967\n",
      "epoch: 1 --- accuracy: 96.29999995231628\n",
      "epoch: 2 --- accuracy: 96.8999981880188\n",
      "epoch: 3 --- accuracy: 97.45000004768372\n",
      "epoch: 4 --- accuracy: 97.60000109672546\n",
      "epoch: 5 --- accuracy: 97.75000214576721\n",
      "epoch: 6 --- accuracy: 97.85000085830688\n",
      "epoch: 7 --- accuracy: 98.00000190734863\n",
      "epoch: 8 --- accuracy: 98.19999933242798\n",
      "epoch: 9 --- accuracy: 98.04999828338623\n",
      "epoch: 10 --- accuracy: 97.89999723434448\n",
      "epoch: 11 --- accuracy: 97.75000214576721\n",
      "epoch: 12 --- accuracy: 98.00000190734863\n",
      "epoch: 13 --- accuracy: 97.89999723434448\n",
      "epoch: 14 --- accuracy: 98.19999933242798\n",
      "epoch: 15 --- accuracy: 98.1000006198883\n",
      "epoch: 16 --- accuracy: 98.1000006198883\n",
      "epoch: 17 --- accuracy: 98.29999804496765\n",
      "epoch: 18 --- accuracy: 98.25000166893005\n",
      "epoch: 19 --- accuracy: 9.449999779462814\n"
     ]
    }
   ],
   "source": [
    "y_cnn_preds = experiment(build_cnn_model, batch_size=512, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0913f5df28d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m88\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cnn_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 88\n",
    "imshow(x_test[idx].reshape(28,28))\n",
    "print('label =', y_cnn_preds[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils: CNN definition\n",
    "credit: https://medium.com/data-science-group-iitr/building-a-convolutional-neural-network-in-python-with-tensorflow-d251c3ca8117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, name):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # shape of the filter-weights for the convolution\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights (filters) with the given shape\n",
    "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "        # Create new biases, one for each filter\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "        layer += biases\n",
    "        \n",
    "        return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_relu_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.relu(input)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_pool_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.max_pool(value=input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input, num_inputs, num_outputs, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "\n",
    "        # Create new weights and biases.\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "        layer = tf.matmul(input, weights) + biases\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
